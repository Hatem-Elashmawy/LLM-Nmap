# LLM-Nmap
We will build a framework where a user can request Nmap scans in natural language. An LLM, integrated through the llm CLI and a custom Nmap tool, will translate the request into an Nmap command, execute it, and summarize the results. The final demo will show that describing the desired analysis to the LLM is enough to configure and run Nmap, collect the output, and present it clearly to the user.

## Project Goal

Use a Large Language Model (LLM) to translate natural-language requests into Nmap scans.  
The framework should:

- Let the user describe the desired analysis in plain English.
- Allow the LLM to configure and run Nmap.
- Capture Nmap’s output.
- Present the results in a clear, summarized format.

## Repo Structure

- `src/` – Python code (Nmap runner, LLM integration, demo scripts)
- `docs/` – Project plan and technical report drafts
- `examples/` – Manual Nmap baselines and demo run outputs
- `results/` – Scan outputs generated by the framework



## Next steps

- Explanation of tools llm and nmap (how it detected open port)
- Opening other ports http, udp, …
- Trying another VM (beebox)
- High light the limits of llm agent (some the answer is not really intersting + random answer)
- Try with another model (chat gpt api)
